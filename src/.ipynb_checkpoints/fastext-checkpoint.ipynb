{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1865e15535d96f2",
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%pip install python-dotenv\n",
    "%pip install requests\n",
    "%pip install gql\n",
    "%pip install requests-toolbelt\n",
    "%pip install pandas\n",
    "%pip install fasttext\n",
    "%pip install numpy\n",
    "%pip install scikit-learn\n",
    "%pip install matplotlib\n",
    "%pip install seaborn\n",
    "%pip install nltk\n",
    "%pip install fpdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae110e465a9b519",
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from gql import Client, gql\n",
    "from gql.transport.requests import RequestsHTTPTransport\n",
    "import re\n",
    "import pandas as pd\n",
    "import gensim.downloader as api\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from gensim.models import KeyedVectors\n",
    "from fpdf import FPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-14T01:16:49.548797200Z"
    }
   },
   "outputs": [],
   "source": [
    "#carrega a chave da API\n",
    "load_dotenv(\"../.env\")\n",
    "token = os.getenv('GH_TOKEN')\n",
    "if token is None:\n",
    "    raise ValueError(\"GitHub token is not set. Check your .env file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64e0d090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the Full taxonomy\n",
    "\n",
    "# TO DO: load the full taxonomy from the csv file\n",
    "# TO DO: create a dictionary with the taxonomy in the pdf\n",
    "\n",
    "# example taxonomy\n",
    "taxonomy = {\n",
    "    'security': ['security', 'vulnerability', 'cve', 'exploit', 'threat', 'attack', 'defense', 'secure', 'risk', 'breach', 'privacy', 'protection', 'cybersecurity', 'secure', 'securely', 'secureness', 'securest', 'securement', 'securements', 'securely' ],\n",
    "    'privacy': ['privacy', 'private', 'personal', 'data', 'pii', 'gdpr', 'ccpa'],\n",
    "    'compliance': ['compliance', 'regulation', 'regulatory', 'law', 'legal', 'audit', 'certification', 'certify', 'certified', 'certifies', 'certifying', 'certifications', 'certificating', 'certificated'],\n",
    "    'ethical': ['ethical', 'ethics', 'moral', 'morality', 'unethical', 'immoral', 'amoral', 'unethically', 'immorally', 'amorally', 'ethically', 'morally', 'ethics', 'morals', 'ethicality', 'ethicalness', 'ethic', 'ethics', 'ethicist', 'ethicists', 'ethicize', 'ethicized', 'ethicizes', 'ethicizing', 'ethicise', 'ethicised', 'ethicises', 'ethicising', 'ethicizable', 'ethicization', 'ethicizations', 'ethicize', 'ethicized', 'ethicizes', 'ethicizing', 'ethicise', 'ethicised', 'ethicises', 'ethicising', 'ethicizable', 'ethicization', 'ethicizations'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff092685",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bf126be85271a20",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-14T01:16:49.568792600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the transport and client\n",
    "from gql import gql, Client\n",
    "from gql.transport.requests import RequestsHTTPTransport\n",
    "\n",
    "transport = RequestsHTTPTransport(\n",
    "    url='https://api.github.com/graphql',\n",
    "    headers={'Authorization': f'token {token}'}\n",
    ")\n",
    "client = Client(transport=transport, fetch_schema_from_transport=False)\n",
    "\n",
    "# Query generator\n",
    "def query_generator(name, owner, first=100, after=None):\n",
    "    \"\"\"\n",
    "    Generate a GraphQL query for fetching issues from a GitHub repository.\n",
    "\n",
    "    Parameters:\n",
    "    name (str): The name of the repository.\n",
    "    owner (str): The owner of the repository.\n",
    "    first (int): Number of issues to fetch per page. Default is 100.\n",
    "    after (str): Cursor for pagination. Default is None.\n",
    "\n",
    "    Returns:\n",
    "    gql: A GraphQL query object.\n",
    "    \"\"\"\n",
    "    query = gql('''\n",
    "    query GetRepositoryInfo($name: String!, $owner: String!, $first: Int!, $after: String) {\n",
    "        repository(owner: $owner, name: $name) {\n",
    "            name\n",
    "            description\n",
    "            issues(first: $first, after: $after) {\n",
    "                edges {\n",
    "                    node {\n",
    "                        body\n",
    "                        createdAt\n",
    "                    }\n",
    "                }\n",
    "                pageInfo {\n",
    "                    hasNextPage\n",
    "                    endCursor\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    ''')\n",
    "    return query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b187dc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the issues from a repo and generate a data matrix\n",
    "def fetch_issues(query_issues):\n",
    "    data_matrix = []  # [issue body, createdAt]\n",
    "\n",
    "    # Execute the queries with pagination using variables\n",
    "    try:\n",
    "        issue_cursor = None \n",
    "\n",
    "        # Pagination loop for issues\n",
    "        while True:\n",
    "            # Execute the query for issues\n",
    "            issues = client.execute(query_issues, variable_values={'issueCursor': issue_cursor})\n",
    "\n",
    "            # Process the issues\n",
    "            for issue in issues['repository']['issues']['edges']:\n",
    "                issue_node = issue['node']\n",
    "                body_text = issue_node['body']\n",
    "                created_at = issue_node['createdAt']\n",
    "\n",
    "                if body_text:  # Only add issues that have a body\n",
    "                    data_matrix.append([body_text, created_at])\n",
    "\n",
    "            # Check if there are more pages to fetch\n",
    "            issue_page_info = issues['repository']['issues']['pageInfo']\n",
    "            if not issue_page_info['hasNextPage']:\n",
    "                print(\"No more issues pages to fetch.\")\n",
    "                break\n",
    "\n",
    "            # Get the cursor to fetch the next page of issues\n",
    "            issue_cursor = issue_page_info['endCursor']\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error executing query: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Output the collected issue data\n",
    "    print(f\"Total issues collected: {len(data_matrix)}\")\n",
    "    return data_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75fe2e43-8aee-4511-b660-a6eb06dfd2d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fasttext'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfasttext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_facebook_vectors\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfasttext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\n\u001b[0;32m      3\u001b[0m fasttext\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mdownload_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m, if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Load pre-trained FastText model\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fasttext'"
     ]
    }
   ],
   "source": [
    "from gensim.models.fasttext import load_facebook_vectors\n",
    "import fasttext.util\n",
    "fasttext.util.download_model('en', if_exists='ignore')\n",
    "\n",
    "# Load pre-trained FastText model\n",
    "fasttext_model = load_facebook_vectors(\"cc.en.300.bin\")  # Replace with the correct path to your FastText model\n",
    "\n",
    "# Function to get the average word vector for a phrase\n",
    "def get_average_word_vector(phrase, model):\n",
    "    words = word_tokenize(phrase.lower())\n",
    "    word_vectors = []\n",
    "\n",
    "    # Use model.get_vector to get a vector for any word (in or out of vocabulary)\n",
    "    for word in words:\n",
    "        try:\n",
    "            word_vectors.append(model.get_vector(word))\n",
    "        except KeyError:\n",
    "            # FastText rarely raises KeyError because it can infer vectors for OOV words\n",
    "            continue\n",
    "\n",
    "    if not word_vectors:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(word_vectors, axis=0)\n",
    "\n",
    "# Function to check if a text matches any category in the taxonomy\n",
    "def isInContext(text, taxonomy, threshold=0.4):\n",
    "    # Get the average word vector for the text\n",
    "    text_vector = get_average_word_vector(text, fasttext_model) \n",
    "\n",
    "    for category, keywords in taxonomy.items():\n",
    "        # Get the average word vector for all keywords in the category\n",
    "        category_vectors = [get_average_word_vector(keyword, fasttext_model) for keyword in keywords]\n",
    "        category_mean_vector = np.mean(category_vectors, axis=0)\n",
    "\n",
    "        # Compute cosine similarity between the text vector and the category vector\n",
    "        similarity = cosine_similarity([text_vector], [category_mean_vector])[0][0]\n",
    "\n",
    "        # If similarity exceeds threshold, consider the text in context\n",
    "        if similarity > threshold:\n",
    "            return True, category  # Return True and the matched category (can be used for further processing)\n",
    "\n",
    "    return False, None  # Return False if no category matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde0d7f4-1990-4399-8092-4d012cf63982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract messages from the issues result\n",
    "def extractMessagesFromIssues(issue_result):\n",
    "    messages_matrix = []\n",
    "\n",
    "    # Get the 'edges' list from the issues result\n",
    "    edges = issue_result['repository']['issues']['edges']\n",
    "\n",
    "    # Loop through the edges to extract the body and createdAt\n",
    "    for edge in edges:\n",
    "        node = edge['node']\n",
    "        body = node.get('body', '').strip()\n",
    "        created_at = node.get('createdAt', '') \n",
    "\n",
    "        # Only append if the body has content (non-empty string)\n",
    "        if body:\n",
    "            messages_matrix.append([body, created_at])\n",
    "    print(f\"Total messages extracted: {len(messages_matrix)}\")\n",
    "    return messages_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e759af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a number of messages graph from the messagesInContext list\n",
    "def getMessagesPerYearGraph(messagesInContext):\n",
    "        \n",
    "    # Criar um DataFrame a partir das mensagens no contexto\n",
    "    df = pd.DataFrame(messagesInContext, columns=['Message', 'CreatedAt'])\n",
    "\n",
    "    # Converter a coluna 'CreatedAt' para o tipo datetime\n",
    "    df['CreatedAt'] = pd.to_datetime(df['CreatedAt'])\n",
    "\n",
    "    # Extrair o ano da coluna 'CreatedAt'\n",
    "    df['Year'] = df['CreatedAt'].dt.year  # Usando .dt.year para obter o ano diretamente\n",
    "\n",
    "    # Agrupar o DataFrame por 'Year' e contar o número de mensagens\n",
    "    yearly_messages = df.groupby('Year').size()\n",
    "\n",
    "    # Plotar o número de mensagens por ano\n",
    "    ax = yearly_messages.plot(kind='bar', title='Número de Mensagens no Contexto por Ano')\n",
    "    ax.set_xlabel('Ano')\n",
    "    ax.set_ylabel('Número de Mensagens')\n",
    "\n",
    "    # Rotacionar os rótulos do eixo X na vertical\n",
    "    plt.xticks(rotation=90)\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd38d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a percent of messages graph from the messagesInContext\n",
    "def getMessagesPerYearGraphPercent(messagesInContext, data_matrix):\n",
    "\n",
    "    # Criar um DataFrame a partir das mensagens no contexto\n",
    "    df_context = pd.DataFrame(messagesInContext, columns=['Message', 'CreatedAt'])\n",
    "\n",
    "    # Criar um DataFrame a partir do total de mensagens\n",
    "    df_total = pd.DataFrame(data_matrix, columns=['Message', 'CreatedAt'])\n",
    "\n",
    "    # Converter a coluna 'CreatedAt' para o tipo datetime para ambos os DataFrames\n",
    "    df_context['CreatedAt'] = pd.to_datetime(df_context['CreatedAt'])\n",
    "    df_total['CreatedAt'] = pd.to_datetime(df_total['CreatedAt'])\n",
    "\n",
    "    # Extrair o ano da coluna 'CreatedAt'\n",
    "    df_context['Year'] = df_context['CreatedAt'].dt.to_period('Y')\n",
    "    df_total['Year'] = df_total['CreatedAt'].dt.to_period('Y')\n",
    "\n",
    "    # Agrupar os DataFrames por 'Year' e contar o número de mensagens\n",
    "    yearly_context_messages = df_context.groupby('Year').size()\n",
    "    yearly_total_messages = df_total.groupby('Year').size()\n",
    "\n",
    "    # Calcular a porcentagem de mensagens no contexto em relação ao total por ano\n",
    "    yearly_percentage = (yearly_context_messages / yearly_total_messages) * 100\n",
    "\n",
    "    # Plotar a porcentagem de mensagens por ano\n",
    "    ax = yearly_percentage.plot(kind='bar', title='Porcentagem de Mensagens no Contexto por Ano')\n",
    "    ax.set_xlabel('Ano')\n",
    "    ax.set_ylabel('Porcentagem de Mensagens (%)')\n",
    "\n",
    "    # Rotacionar os rótulos do eixo X na vertical\n",
    "    plt.xticks(rotation=90)\n",
    "\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a9fb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a sample of messages graph from the messagesInContext\n",
    "def sampleGenerator(messagesInContext):\n",
    "    # Definir o tamanho da amostra\n",
    "    sample_size = 2\n",
    "    \n",
    "    # Get 2 random strings \n",
    "    sample = random.sample(messagesInContext, sample_size)\n",
    "    \n",
    "    semple_string= f'Sample of {sample_size} messages in context:\\n' + sample[0][0] + '\\n' + sample[1][0]\n",
    "    \n",
    "    return semple_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798239c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fpdf import FPDF\n",
    "\n",
    "class PDF(FPDF):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.set_auto_page_break(auto=True, margin=15)\n",
    "        self.add_font(\"DejaVu\", fname=\"DejaVuSans.ttf\", uni=True)\n",
    "        self.set_font(\"DejaVu\", size=12)\n",
    "\n",
    "    @staticmethod\n",
    "    def sanitize_text(text):\n",
    "        \"\"\"Sanitize text to remove unsupported characters.\"\"\"\n",
    "        return ''.join(c if ord(c) < 128 else '?' for c in text)\n",
    "\n",
    "    def add_repository_page(self, name, owner, graph_mpy_path, graph_mpyp_path, sample_text):\n",
    "        # Add a new page for the repository\n",
    "        self.add_page()\n",
    "        \n",
    "        # Sanitize input text\n",
    "        name = self.sanitize_text(name)\n",
    "        owner = self.sanitize_text(owner)\n",
    "        sample_text = self.sanitize_text(sample_text)\n",
    "        \n",
    "        # Title\n",
    "        self.cell(0, 10, f\"Repository: {name} (Owner: {owner})\", ln=True, align='C')\n",
    "        self.ln(10)\n",
    "        \n",
    "        # Add graphs\n",
    "        try:\n",
    "            self.image(graph_mpy_path, x=10, y=self.get_y(), w=90)\n",
    "            self.set_y(self.get_y() + 90)\n",
    "        except RuntimeError as e:\n",
    "            self.cell(0, 10, \"Error loading graph_mpy image.\", ln=True)\n",
    "        \n",
    "        try:\n",
    "            self.image(graph_mpyp_path, x=10, y=self.get_y(), w=90)\n",
    "            self.set_y(self.get_y() + 90)\n",
    "        except RuntimeError as e:\n",
    "            self.cell(0, 10, \"Error loading graph_mpyp image.\", ln=True)\n",
    "        \n",
    "        # Add the sample text\n",
    "        self.ln(10)\n",
    "        self.multi_cell(0, 10, f\"Sample:\\n{sample_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0eef38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        name symbol       owner          repo  total_issues\n",
      "0  Avalanche   AVAX    ava-labs   avalanchego           244\n",
      "1       Beam   BEAM      BeamMW          beam           237\n",
      "2    Bitcoin    BTC     bitcoin       bitcoin           653\n",
      "3   Dogecoin   DOGE    dogecoin      dogecoin           227\n",
      "4   Polkadot    DOT  paritytech  polkadot-sdk          1784\n",
      "Processing repository: avalanchego (Owner: ava-labs)\n",
      "No more issues pages to fetch.\n",
      "Data size: 771\n",
      "Messages in context: 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:15: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_context['Year'] = df_context['CreatedAt'].dt.to_period('Y')\n",
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:16: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_total['Year'] = df_total['CreatedAt'].dt.to_period('Y')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing repository: beam (Owner: BeamMW)\n",
      "No more issues pages to fetch.\n",
      "Data size: 1610\n",
      "Messages in context: 965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:15: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_context['Year'] = df_context['CreatedAt'].dt.to_period('Y')\n",
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:16: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_total['Year'] = df_total['CreatedAt'].dt.to_period('Y')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing repository: bitcoin (Owner: bitcoin)\n",
      "No more issues pages to fetch.\n",
      "Data size: 8115\n",
      "Messages in context: 4579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:15: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_context['Year'] = df_context['CreatedAt'].dt.to_period('Y')\n",
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:16: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_total['Year'] = df_total['CreatedAt'].dt.to_period('Y')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing repository: dogecoin (Owner: dogecoin)\n",
      "No more issues pages to fetch.\n",
      "Data size: 1240\n",
      "Messages in context: 703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:15: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_context['Year'] = df_context['CreatedAt'].dt.to_period('Y')\n",
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:16: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_total['Year'] = df_total['CreatedAt'].dt.to_period('Y')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing repository: polkadot-sdk (Owner: paritytech)\n",
      "No more issues pages to fetch.\n",
      "Data size: 2581\n",
      "Messages in context: 1804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:15: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_context['Year'] = df_context['CreatedAt'].dt.to_period('Y')\n",
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:16: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_total['Year'] = df_total['CreatedAt'].dt.to_period('Y')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing repository: go-ethereum (Owner: ethereum)\n",
      "No more issues pages to fetch.\n",
      "Data size: 8035\n",
      "Messages in context: 3781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:15: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_context['Year'] = df_context['CreatedAt'].dt.to_period('Y')\n",
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:16: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_total['Year'] = df_total['CreatedAt'].dt.to_period('Y')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing repository: ic (Owner: dfinity)\n",
      "No more issues pages to fetch.\n",
      "Data size: 0\n",
      "Messages in context: 0\n",
      "Processing repository: chainlink (Owner: smartcontractkit)\n",
      "No more issues pages to fetch.\n",
      "Data size: 428\n",
      "Messages in context: 321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:15: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_context['Year'] = df_context['CreatedAt'].dt.to_period('Y')\n",
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:16: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_total['Year'] = df_total['CreatedAt'].dt.to_period('Y')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing repository: neo (Owner: neo-project)\n",
      "No more issues pages to fetch.\n",
      "Data size: 1409\n",
      "Messages in context: 874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:15: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_context['Year'] = df_context['CreatedAt'].dt.to_period('Y')\n",
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:16: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_total['Year'] = df_total['CreatedAt'].dt.to_period('Y')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing repository: stellar-core (Owner: stellar)\n",
      "No more issues pages to fetch.\n",
      "Data size: 1635\n",
      "Messages in context: 986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:15: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_context['Year'] = df_context['CreatedAt'].dt.to_period('Y')\n",
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:16: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_total['Year'] = df_total['CreatedAt'].dt.to_period('Y')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing repository: monero (Owner: monero-project)\n",
      "No more issues pages to fetch.\n",
      "Data size: 3066\n",
      "Messages in context: 1706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:15: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_context['Year'] = df_context['CreatedAt'].dt.to_period('Y')\n",
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:16: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_total['Year'] = df_total['CreatedAt'].dt.to_period('Y')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing repository: rippled (Owner: ripple)\n",
      "No more issues pages to fetch.\n",
      "Data size: 1384\n",
      "Messages in context: 869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:15: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_context['Year'] = df_context['CreatedAt'].dt.to_period('Y')\n",
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:16: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_total['Year'] = df_total['CreatedAt'].dt.to_period('Y')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing repository: metamask-extension (Owner: MetaMask)\n",
      "No more issues pages to fetch.\n",
      "Data size: 11278\n",
      "Messages in context: 6304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:15: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_context['Year'] = df_context['CreatedAt'].dt.to_period('Y')\n",
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:16: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_total['Year'] = df_total['CreatedAt'].dt.to_period('Y')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing repository: mina (Owner: MinaProtocol)\n",
      "No more issues pages to fetch.\n",
      "Data size: 4462\n",
      "Messages in context: 2454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:15: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_context['Year'] = df_context['CreatedAt'].dt.to_period('Y')\n",
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:16: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_total['Year'] = df_total['CreatedAt'].dt.to_period('Y')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing repository: osmosis (Owner: osmosis-labs)\n",
      "No more issues pages to fetch.\n",
      "Data size: 2160\n",
      "Messages in context: 695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:15: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_context['Year'] = df_context['CreatedAt'].dt.to_period('Y')\n",
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:16: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_total['Year'] = df_total['CreatedAt'].dt.to_period('Y')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing repository: oasis-core (Owner: oasisprotocol)\n",
      "No more issues pages to fetch.\n",
      "Data size: 1814\n",
      "Messages in context: 1248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:15: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_context['Year'] = df_context['CreatedAt'].dt.to_period('Y')\n",
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:16: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_total['Year'] = df_total['CreatedAt'].dt.to_period('Y')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing repository: zcash (Owner: zcash)\n",
      "No more issues pages to fetch.\n",
      "Data size: 3576\n",
      "Messages in context: 2010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:15: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_context['Year'] = df_context['CreatedAt'].dt.to_period('Y')\n",
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:16: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_total['Year'] = df_total['CreatedAt'].dt.to_period('Y')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing repository: storj (Owner: storj)\n",
      "No more issues pages to fetch.\n",
      "Data size: 2593\n",
      "Messages in context: 1856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:15: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_context['Year'] = df_context['CreatedAt'].dt.to_period('Y')\n",
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:16: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_total['Year'] = df_total['CreatedAt'].dt.to_period('Y')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing repository: chia-blockchain (Owner: Chia-Network)\n",
      "No more issues pages to fetch.\n",
      "Data size: 4911\n",
      "Messages in context: 2049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:15: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_context['Year'] = df_context['CreatedAt'].dt.to_period('Y')\n",
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:16: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_total['Year'] = df_total['CreatedAt'].dt.to_period('Y')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing repository: eos (Owner: EOSIO)\n",
      "No more issues pages to fetch.\n",
      "Data size: 4848\n",
      "Messages in context: 2574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:15: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_context['Year'] = df_context['CreatedAt'].dt.to_period('Y')\n",
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:16: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_total['Year'] = df_total['CreatedAt'].dt.to_period('Y')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing repository: cowswap (Owner: gnosis)\n",
      "No more issues pages to fetch.\n",
      "Data size: 1224\n",
      "Messages in context: 730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:15: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_context['Year'] = df_context['CreatedAt'].dt.to_period('Y')\n",
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:16: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_total['Year'] = df_total['CreatedAt'].dt.to_period('Y')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing repository: mobilecoin (Owner: mobilecoinfoundation)\n",
      "No more issues pages to fetch.\n",
      "Data size: 402\n",
      "Messages in context: 235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:15: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_context['Year'] = df_context['CreatedAt'].dt.to_period('Y')\n",
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:16: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_total['Year'] = df_total['CreatedAt'].dt.to_period('Y')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing repository: steem (Owner: steemit)\n",
      "No more issues pages to fetch.\n",
      "Data size: 2129\n",
      "Messages in context: 1007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:15: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_context['Year'] = df_context['CreatedAt'].dt.to_period('Y')\n",
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:16: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_total['Year'] = df_total['CreatedAt'].dt.to_period('Y')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing repository: steem (Owner: steemit)\n",
      "No more issues pages to fetch.\n",
      "Data size: 2129\n",
      "Messages in context: 1007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:15: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_context['Year'] = df_context['CreatedAt'].dt.to_period('Y')\n",
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:16: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_total['Year'] = df_total['CreatedAt'].dt.to_period('Y')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing repository: open-chat (Owner: open-chat-labs)\n",
      "No more issues pages to fetch.\n",
      "Data size: 533\n",
      "Messages in context: 165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:15: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_context['Year'] = df_context['CreatedAt'].dt.to_period('Y')\n",
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:16: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_total['Year'] = df_total['CreatedAt'].dt.to_period('Y')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing repository: origin-dollar (Owner: OriginProtocol)\n",
      "No more issues pages to fetch.\n",
      "Data size: 707\n",
      "Messages in context: 453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:15: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_context['Year'] = df_context['CreatedAt'].dt.to_period('Y')\n",
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:16: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_total['Year'] = df_total['CreatedAt'].dt.to_period('Y')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing repository: ic (Owner: dfinity)\n",
      "No more issues pages to fetch.\n",
      "Data size: 0\n",
      "Messages in context: 0\n",
      "Processing repository: red (Owner: red)\n",
      "No more issues pages to fetch.\n",
      "Data size: 4002\n",
      "Messages in context: 439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:15: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_context['Year'] = df_context['CreatedAt'].dt.to_period('Y')\n",
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:16: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_total['Year'] = df_total['CreatedAt'].dt.to_period('Y')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing repository: go-ethereum (Owner: ethereum)\n",
      "No more issues pages to fetch.\n",
      "Data size: 8035\n",
      "Messages in context: 3781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:15: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_context['Year'] = df_context['CreatedAt'].dt.to_period('Y')\n",
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:16: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_total['Year'] = df_total['CreatedAt'].dt.to_period('Y')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing repository: agoric-sdk (Owner: Agoric)\n",
      "No more issues pages to fetch.\n",
      "Data size: 4371\n",
      "Messages in context: 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:15: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_context['Year'] = df_context['CreatedAt'].dt.to_period('Y')\n",
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:16: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_total['Year'] = df_total['CreatedAt'].dt.to_period('Y')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing repository: holochain-rust (Owner: holochain)\n",
      "No more issues pages to fetch.\n",
      "Data size: 488\n",
      "Messages in context: 211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:15: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_context['Year'] = df_context['CreatedAt'].dt.to_period('Y')\n",
      "C:\\Users\\belfo\\AppData\\Local\\Temp\\ipykernel_10672\\2609541548.py:16: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_total['Year'] = df_total['CreatedAt'].dt.to_period('Y')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF report saved to full_report.pdf\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import random  # Optional: for simulating occasional failures during testing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Retry logic function\n",
    "def execute_with_retries(client, query, variables, max_retries=5, delay=2):\n",
    "    \"\"\"\n",
    "    Executes a GraphQL query with retry logic.\n",
    "    \n",
    "    Parameters:\n",
    "        client (object): The GraphQL client.\n",
    "        query (str): The GraphQL query string.\n",
    "        variables (dict): The query variables.\n",
    "        max_retries (int): Maximum number of retries.\n",
    "        delay (int): Delay in seconds between retries.\n",
    "        \n",
    "    Returns:\n",
    "        dict: The result of the GraphQL query.\n",
    "    \"\"\"\n",
    "    attempt = 0\n",
    "    while attempt < max_retries:\n",
    "        try:\n",
    "            # Execute the query\n",
    "            return client.execute(query, variable_values=variables)\n",
    "        except ConnectionError as e:\n",
    "            attempt += 1\n",
    "            print(f\"Connection error occurred: {e}. Attempt {attempt}/{max_retries}. Retrying in {delay} seconds...\")\n",
    "            time.sleep(delay)\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred: {e}\")\n",
    "            raise  # Re-raise non-connection-related exceptions\n",
    "    print(f\"Failed to execute query after {max_retries} retries.\")\n",
    "    raise ConnectionError(\"Max retries exceeded.\")\n",
    "\n",
    "# Load the filtered repositories data\n",
    "df = pd.read_csv('filtered_repositories_over_200_issues.csv')\n",
    "print(df.head())\n",
    "\n",
    "# Initialize the PDF\n",
    "pdf = PDF()\n",
    "\n",
    "# Iterate through each repository in the dataset\n",
    "for index, row in df.iterrows():\n",
    "    # Extract repository details\n",
    "    name = row['repo']\n",
    "    owner = row['owner']\n",
    "    \n",
    "    print(f\"Processing repository: {name} (Owner: {owner})\")\n",
    "    issue_cursor = None\n",
    "    data_matrix = []  # [issue body, createdAt]\n",
    "\n",
    "    # Fetch issues with retry logic\n",
    "    while True:\n",
    "        query = query_generator(name, owner, first=100, after=issue_cursor)\n",
    "        variables = {'name': name, 'owner': owner, 'first': 100, 'after': issue_cursor}\n",
    "        \n",
    "        try:\n",
    "            issues = execute_with_retries(client, query, variables)\n",
    "        except ConnectionError:\n",
    "            print(f\"Failed to fetch issues for repository {name}. Moving to next repository.\")\n",
    "            break  # Exit the loop for this repository\n",
    "        \n",
    "        # Process the issues\n",
    "        for issue in issues['repository']['issues']['edges']:\n",
    "            issue_node = issue['node']\n",
    "            body_text = issue_node['body']\n",
    "            created_at = issue_node['createdAt']\n",
    "            if body_text:\n",
    "                data_matrix.append([body_text, created_at])\n",
    "        \n",
    "        # Check if there are more pages to fetch\n",
    "        issue_page_info = issues['repository']['issues']['pageInfo']\n",
    "        if not issue_page_info['hasNextPage']:\n",
    "            print(\"No more issues pages to fetch.\")\n",
    "            break\n",
    "        \n",
    "        # Get the cursor for the next page\n",
    "        issue_cursor = issue_page_info['endCursor']\n",
    "    \n",
    "    print(f\"Data size: {len(data_matrix)}\")\n",
    "    \n",
    "    # Filter messages based on context using the taxonomy\n",
    "    messages_in_context = []\n",
    "    for message in data_matrix:\n",
    "        text = message[0]\n",
    "        in_context, category = isInContext(text, taxonomy)\n",
    "        if in_context:\n",
    "            messages_in_context.append([text, message[1]])\n",
    "    \n",
    "    print(f\"Messages in context: {len(messages_in_context)}\")\n",
    "    \n",
    "    # Generate and save visualizations\n",
    "    if messages_in_context:\n",
    "        # Messages per year graph\n",
    "        graph_mpy_path = f\"graphs/{name}_messages_per_year.png\"\n",
    "        graph_mpy_ax = getMessagesPerYearGraph(messages_in_context)\n",
    "        plt.savefig(graph_mpy_path)\n",
    "        plt.close(graph_mpy_ax.figure)\n",
    "        \n",
    "        # Messages per year percentage graph\n",
    "        graph_mpyp_path = f\"graphs/{name}_messages_per_year_percent.png\"\n",
    "        graph_mpyp_ax = getMessagesPerYearGraphPercent(messages_in_context, data_matrix)\n",
    "        plt.savefig(graph_mpyp_path)\n",
    "        plt.close(graph_mpyp_ax.figure)\n",
    "        \n",
    "        # Generate the sample text\n",
    "        sample_text = sampleGenerator(messages_in_context)\n",
    "    else:\n",
    "        # Handle cases with no relevant messages\n",
    "        erro_msg = \"No messages in context\" if data_matrix else \"No issues found\"\n",
    "        \n",
    "        # Generate empty graphs with an appropriate title\n",
    "        graph_mpy_path = f\"graphs/{name}_messages_per_year.png\"\n",
    "        plt.figure()\n",
    "        plt.title(erro_msg)\n",
    "        plt.savefig(graph_mpy_path)\n",
    "        plt.close()\n",
    "        \n",
    "        graph_mpyp_path = f\"graphs/{name}_messages_per_year_percent.png\"\n",
    "        plt.figure()\n",
    "        plt.title(erro_msg)\n",
    "        plt.savefig(graph_mpyp_path)\n",
    "        plt.close()\n",
    "        \n",
    "        sample_text = erro_msg\n",
    "    \n",
    "    # Add repository data to the PDF\n",
    "    pdf.add_repository_page(name, owner, graph_mpy_path, graph_mpyp_path, sample_text)\n",
    "    \n",
    "    # Pause briefly to prevent API rate limits or overloading\n",
    "    time.sleep(1)\n",
    "\n",
    "# Save the PDF report\n",
    "output_pdf_path = \"full_report.pdf\"\n",
    "pdf.output(output_pdf_path)\n",
    "print(f\"PDF report saved to {output_pdf_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
